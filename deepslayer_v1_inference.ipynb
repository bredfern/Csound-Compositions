{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepslayer-v1-inference.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bredfern/CsoundCompositions/blob/master/deepslayer_v1_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-_lIDRqzwlQ"
      },
      "source": [
        "# DeepSlayerXL (Rev. 1) 𖤐\n",
        "\n",
        "An autoregressive multi-instrument multi-track music model based on TransformerXL (~100m parameters). Trained on 3,600 metal songs from the 80s-2010s.\n",
        "\n",
        "Set hardware accelerator to GPU in \"Runtime\" -> \"Change runtime type\" to unleash the rage of the machine. \n",
        "\n",
        "## 1. Download model and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsuMFOI-zL2g"
      },
      "source": [
        "!gdown --id 1hIEQm5mwq0zfcXhHvq26fsuY8fTliWUI\n",
        "\n",
        "!unzip /content/deepslayerxl-v1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8gMcrZYGUvS"
      },
      "source": [
        "!apt install fluidsynth\n",
        "\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
        "\n",
        "!pip install transformers music21==6.7.1 transformers==4.9.1 midi2audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tKPpCmoPfby"
      },
      "source": [
        "## 2. Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfJMYYh63qoM"
      },
      "source": [
        "import sys\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    TransfoXLLMHeadModel,\n",
        "    TransfoXLTokenizer,\n",
        ")\n",
        "\n",
        "sys.path.append('/content/deepslayerxl-v1')\n",
        "\n",
        "from musicprocessing import *\n",
        "\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "tokenizer = TransfoXLTokenizer(\n",
        "    vocab_file='/content/deepslayerxl-v1/vocab.txt',\n",
        "    unk_token='UNK',\n",
        "    eos_token='EOS',\n",
        ")\n",
        "\n",
        "tokenizer.add_special_tokens(\n",
        "    {\n",
        "        \"bos_token\": \"BOS\",\n",
        "        \"pad_token\": \"PAD\",\n",
        "    }\n",
        ")\n",
        "\n",
        "model = TransfoXLLMHeadModel.from_pretrained(\"/content/deepslayerxl-v1/\").to(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    \n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    n_beams = 2\n",
        "\n",
        "\n",
        "def makeSong(\n",
        "    song_ids: List,\n",
        "    filename: str,\n",
        "    min_length: int = 512,\n",
        "    max_length: int = 768,\n",
        "    slide = 256,\n",
        "    step = 16,\n",
        "    temperature: float = 0.9,\n",
        "    top_k: int = 32,\n",
        "    num_beams: int = 3\n",
        "    ):\n",
        "\n",
        "  while True:\n",
        "\n",
        "      if len(song_ids) > slide:\n",
        "          _input_ids = song_ids[-slide:]\n",
        "          input_len = slide\n",
        "      else:\n",
        "          _input_ids = song_ids\n",
        "          input_len = len(_input_ids)\n",
        "\n",
        "      _input_ids = torch.LongTensor([_input_ids]).to(device)\n",
        "\n",
        "      outputs = model.generate(\n",
        "          _input_ids,\n",
        "          do_sample=True,\n",
        "          min_length=min_length,\n",
        "          max_length=input_len+step,\n",
        "          top_k=top_k,\n",
        "          temperature=temperature,\n",
        "          num_beams=num_beams,\n",
        "          no_repeat_ngram_size=32,\n",
        "      )\n",
        "\n",
        "      song_ids += outputs[0].tolist()[input_len:]\n",
        "\n",
        "      generated = tokenizer.decode(torch.LongTensor(song_ids))\n",
        "\n",
        "      print(\"[TOKENS: {}] {}\".format(len(song_ids), generated))\n",
        "\n",
        "      if tokenizer.eos_token_id in outputs[0] or len(song_ids) > max_length:\n",
        "          break\n",
        "\n",
        "  print(\"\\n--- GENERATED SONG:\\n{}\\n\".format(generated))\n",
        "\n",
        "  outSeq = generated.split(\" \")\n",
        "\n",
        "  (instrumentsDict, percussionDict) = untokenizeSong(outSeq)\n",
        "\n",
        "  dictsToMidiFile(filename, instrumentsDict, percussionDict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTTN7Ye8Pmft"
      },
      "source": [
        "## 3. Create a song\n",
        "\n",
        "Execute the cell below to create a MIDI file. The MIN_LEN & MAX_LEN variables determine the length of the generated sequence.\n",
        "\n",
        "Note: The first couple of bars may sometimes resemble songs from training data, let it run longer to generate original content. Don't forget to share your creations!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq2zgcLQ47--"
      },
      "source": [
        "# Settings\n",
        "\n",
        "MIN_LEN = 256\n",
        "MAX_LEN = 1024\n",
        "TEMPERATURE = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3OqJwixZ0Wn"
      },
      "source": [
        "*From scratch*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYXVLg9VZS3o"
      },
      "source": [
        "torch.seed()\n",
        "random.seed()\n",
        "\n",
        "start_seq = model.generate(\n",
        "        tokenizer.encode(\"BAR\", return_tensors='pt'),\n",
        "        output_scores=True,\n",
        "        do_sample=True,\n",
        "        max_length=8,\n",
        "    )\n",
        "\n",
        "song_ids = start_seq[0].tolist()\n",
        "\n",
        "makeSong(song_ids, \n",
        "         \"output.mid\",\n",
        "         min_length=MIN_LEN,\n",
        "         max_length=MAX_LEN,\n",
        "         temperature=TEMPERATURE        \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2sXOYGzmR8p"
      },
      "source": [
        "## 4. Listen in the browser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JxtwadKmPGt"
      },
      "source": [
        "Convert your MIDI output to a .wav file to download or listen directly in the browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1yahVoPjUvk"
      },
      "source": [
        "from IPython.display import Audio\n",
        "from midi2audio import FluidSynth\n",
        "\n",
        "FluidSynth(\"font.sf2\").midi_to_audio(\"output.mid\", 'play.wav')\n",
        "Audio(\"play.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBNH5fwmi6iN"
      },
      "source": [
        "## 5. Alternatively, create a song from a prompt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKWiaRWti3mo"
      },
      "source": [
        "# Bulls on Parade!\n",
        "\n",
        "start_seq = \"BAR DRUM40 DRUM36 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D1 P41 DRUM49 DRUM46 DRUM36 | I30D3 P41 I30D3 P48 I34D3 P29 DRUM36 | DRUM46 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D2 P41 DRUM36 DRUM46 DRUM40 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D1 P41 DRUM46 DRUM36 | I30D3 P41 I30D3 P48 I34D3 P29 DRUM36 | DRUM46 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D2 P41 DRUM46 DRUM36 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D1 P41 DRUM36 DRUM46 DRUM40 | I30D3 P41 I30D3 P48 I34D3 P29 | BAR DRUM46 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D1 P41 DRUM46 DRUM36 | I30D3 P41 I30D3 P48 I34D3 P29 DRUM36 | DRUM46 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D2 P41 DRUM36 DRUM46 DRUM40 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D1 P41 DRUM46 DRUM36 | I30D3 P41 I30D3 P48 I34D3 P29 DRUM36 | DRUM46 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D2 P41 DRUM46 DRUM36 | | I30D1 P65 I30D1 P60 I30D1 P53 I34D1 P41 DRUM36 DRUM46 DRUM40 | I30D3 P41 I30D3 P48 I34D3 P29 | \"\n",
        "\n",
        "song_ids = tokenizer.convert_to_tensor(start_seq.split(\" \")).tolist()\n",
        "\n",
        "makeSong(song_ids, \"output.mid\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}